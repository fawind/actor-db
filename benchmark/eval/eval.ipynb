{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Amazing Benchmark Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set path to log directory here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = \"/Users/law/drive/msc/m3/adb/bm_results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Run all cells and all the plots will magically appear :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class BMRunInfo:\n",
    "    def __init__(self, bm_type, bm_infos, final_info):\n",
    "        self.bm_type = bm_type\n",
    "        self.bm_infos = bm_infos\n",
    "        self.final_info = final_info\n",
    "\n",
    "# Example line (no linebreaks)\n",
    "# 2018-08-12 18:56:45:761 10 sec: 4262 operations; 426.2 current ops/sec; est completion in 1 hour 18 minutes \n",
    "# [INSERT: Count=4266, Max=951807, Min=2522, Avg=12826.31, 90=16719, 99=58399, 99.9=947199, 99.99=951807]\n",
    "\n",
    "BM_INFO_RE = re.compile(r'^\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}:\\d{3} (\\d{2,}) sec: (\\d+) operations; (\\d*.\\d*) current ops/sec; .* \\[[A-Z]+: Count=(\\d*), Max=(\\d*), Min=(\\d*), Avg=(\\d*.\\d*|\\d*), 90=(\\d*), 99=(\\d*), 99\\.9=(\\d*), 99\\.99=(\\d*)\\]')\n",
    "\n",
    "class BMInfo:\n",
    "    def __init__(self, log_line):\n",
    "        match = BM_INFO_RE.match(log_line)\n",
    "        if match is None:\n",
    "            raise ValueError(\"Bad log line: \" + log_line)\n",
    "        self.seconds = match.group(1)\n",
    "        self.total_ops = match.group(2)\n",
    "        self.ops_per_sec = match.group(3)\n",
    "        self.ops_per_interval = match.group(4)\n",
    "        self.max_latency = match.group(5)\n",
    "        self.min_latency = match.group(6)\n",
    "        self.avg_latecny = match.group(7)\n",
    "        self.p90 = match.group(8)\n",
    "        self.p99 = match.group(9)\n",
    "        self.p999 = match.group(10)\n",
    "        self.p9999 = match.group(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bm_run_from_file(file_name):\n",
    "    bm_infos = []\n",
    "    final_info = {}\n",
    "    bm_type = \"\"\n",
    "    for line in open(file_name):\n",
    "        if line.startswith(\"2018-\") and \"0 sec: 0 operations;\" not in line:\n",
    "            bm_infos.append(BMInfo(line))\n",
    "            \n",
    "        # [INSERT], AverageLatency(us), 1851.142024\n",
    "        # [OVERALL], Throughput(ops/sec), 8293.62759124027\n",
    "        # [READ], AverageLatency(us), 1948.265838\n",
    "        elif line.startswith(\"[INSERT],\") or line.startswith(\"[OVERALL],\") or line.startswith(\"[READ],\"):\n",
    "            split_line = line.split(', ')\n",
    "            final_info[split_line[1]] = int(float(split_line[2].strip()))\n",
    "\n",
    "        if line.startswith('[INSERT]'):\n",
    "            bm_type = \"INSERT\"\n",
    "        elif line.startswith('[READ]'):\n",
    "            bm_type = \"READ\"\n",
    "        \n",
    "    return BMRunInfo(bm_type, bm_infos, final_info)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "RUN_FILE_RE = re.compile(r\"^(run_\\d{1,2}-)\")\n",
    "\n",
    "def get_bm_runs(log_dir):\n",
    "    print(log_dir)\n",
    "    runs = defaultdict(list)\n",
    "    for dir_path, dirs, files in os.walk(log_dir):\n",
    "        for file in files:\n",
    "            if not (file.endswith(\".txt\") or file.endswith(\".log\")) or file.endswith(\"FAILED.txt\"):\n",
    "                continue\n",
    "            \n",
    "            run_prefix = RUN_FILE_RE.match(file)\n",
    "            if run_prefix is not None:\n",
    "                file_key = file[len(run_prefix.group(1)):]            \n",
    "            else:\n",
    "                file_key = file\n",
    "            \n",
    "            runs[file_key].append(get_bm_run_from_file(os.path.join(dir_path, file)))\n",
    "    return runs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_final_info(runs, file_type):\n",
    "    res = defaultdict(list)\n",
    "    for file, runs in runs.items():\n",
    "        if file.startswith(file_type):\n",
    "            for run in runs:\n",
    "                res[file].append(run.final_info)\n",
    "                \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUNS = get_bm_runs(LOG_DIR)\n",
    "LOADS = get_final_info(RUNS, 'load')\n",
    "READS = get_final_info(RUNS, 'read')  # or 'run'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(RUNS)\n",
    "print(LOADS)\n",
    "print(READS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capacity_from_file(file):\n",
    "    # read_capacity_1000-num_stores_1.txt\n",
    "    match = re.search(r'capacity_(\\d*)', file)\n",
    "    if match is None:\n",
    "        raise ValueError(\"bad file name: \" + file)\n",
    "    \n",
    "    return int(match.group(1))\n",
    "\n",
    "def r_w_from_file(file):\n",
    "    match = re.search(r'r(\\d+)_w(\\d+)', file)\n",
    "    if match is None:\n",
    "        raise ValueError(\"bad file name: \" + file)\n",
    "        \n",
    "    return int(match.group(1)), int(match.group(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True, 'pgf.rcfonts' : False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metric_single_line(runs, metric, capacity, name):\n",
    "    print('%8d' % capacity, sorted(list(run[metric] for run in runs[f\"{name}_capacity_{capacity}-num_stores_1.txt\"])))\n",
    "\n",
    "def print_metric_single(runs, metric, name):\n",
    "    capacities = [1000, 10000, 50000, 100000, 250000, 500000, 1000000, 10000000]\n",
    "    print(\"\\n\")\n",
    "    print(name, metric)\n",
    "    for cap in capacities:\n",
    "        print_metric_single_line(runs, metric, cap, name)\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    for metric in metrics:\n",
    "        print_metric_single(LOADS, metric, \"load\")\n",
    "        print_metric_single(READS, metric, \"read\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_quorum_metric_line(runs, metric, r, w, name):\n",
    "    # load_n50_r17_w34.log\n",
    "    print('R: %2d, W: %2d' % (r, w), sorted(list(run[metric] for run in runs[f\"{name}_n50_r{r}_w{w}.log\"])))\n",
    "    \n",
    "def print_quorum_metric_single(runs, metric, name):\n",
    "    quorum = [(1, 50), (13, 38), (17, 34), (25, 26)]\n",
    "    print(\"\\n\")\n",
    "    print(name, metric)\n",
    "    for r, w in quorum:\n",
    "        print_quorum_metric_line(runs, metric, r, w, name)\n",
    "\n",
    "def print_quorum_metrics(metrics):\n",
    "    for metric in metrics:\n",
    "        print_quorum_metric_single(LOADS, metric, \"load\")\n",
    "        print_quorum_metric_single(READS, metric, \"run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFO_NAMES = [\n",
    "    ('Throughput(ops/sec)', 'throughput'),\n",
    "#     ('RunTime(ms)', 'runtime'),\n",
    "    ('AverageLatency(us)', 'avg_latency'),\n",
    "#     ('MinLatency(us)', 'min_latency'),\n",
    "#     ('MaxLatency(us)', 'max_latency'),\n",
    "#     ('95thPercentileLatency(us)', '95p_latency'),\n",
    "    ('99thPercentileLatency(us)', '99p_latency')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_nested_max(a, b):\n",
    "    max_a = max([max(x) for x in a])\n",
    "    max_b = max([max(x) for x in b])\n",
    "    return max(max_a, max_b)\n",
    "\n",
    "def get_info_per_capacity(runs, info_name):\n",
    "    cap_final_infos = []\n",
    "    for file, infos in runs.items():\n",
    "        cap = capacity_from_file(file)\n",
    "        info_list = []\n",
    "        for info in infos:    \n",
    "            info_list.append(info[info_name])\n",
    "        cap_final_infos.append((cap, info_list))\n",
    "        \n",
    "    cap_final_infos.sort(key=lambda x: x[0])\n",
    "    caps, infos = list(zip(*cap_final_infos))\n",
    "    return caps, infos\n",
    "\n",
    "def get_info_quorum(runs, info_name):\n",
    "    quorum_final_infos = []\n",
    "    for file, infos in runs.items():\n",
    "        r, w = r_w_from_file(file)\n",
    "        info_list = []\n",
    "\n",
    "        for info in infos:\n",
    "            info_list.append(info[info_name])\n",
    "        quorum_final_infos.append(((r, w), info_list))\n",
    "        \n",
    "    quorum_final_infos.sort(key=lambda x: x[0])\n",
    "    quorums, infos = list(zip(*quorum_final_infos))\n",
    "    return quorums, infos\n",
    "\n",
    "def plot_info_per_capacity(info_name, out_file_name, save_fig = False):\n",
    "    print(info_name, \"\\n\" + (\"=\") * len(info_name))\n",
    "    load_caps, load_infos = get_info_per_capacity(LOADS, info_name)\n",
    "    read_caps, read_infos = get_info_per_capacity(READS, info_name)\n",
    "\n",
    "    max_ylim = get_nested_max(load_infos, read_infos) * 1.1\n",
    "    \n",
    "    ############ LOAD ############ \n",
    "    plt.boxplot(load_infos, labels=[str(x) for x in load_caps], showfliers=False, whis=\"range\")\n",
    "    plt.ylabel(info_name)\n",
    "    plt.xlabel(\"Partition capacity\")\n",
    "    plt.ylim(ymin=0, ymax=max_ylim)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend([\"INSERT\"])\n",
    "\n",
    "    if save_fig:\n",
    "        plt.savefig(f\"load_{out_file_name}.svg\")\n",
    "        plt.savefig(f\"load_{out_file_name}.pgf\")\n",
    "        plt.savefig(f\"load_{out_file_name}.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    ############ READ ############     \n",
    "    plt.boxplot(read_infos, labels=[str(x) for x in read_caps], showfliers=False, whis=\"range\")\n",
    "    plt.ylabel(info_name)\n",
    "    plt.xlabel(\"Partition capacity\")\n",
    "    plt.ylim(ymin=0, ymax=max_ylim)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend([\"READ\"])\n",
    "\n",
    "    if save_fig:\n",
    "        plt.savefig(f\"read_{out_file_name}.svg\")\n",
    "        plt.savefig(f\"read_{out_file_name}.pgf\")\n",
    "        plt.savefig(f\"read_{out_file_name}.png\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_quorum_size(info_name, out_file_name, save_fig = False):\n",
    "    print(info_name, \"\\n\" + (\"=\") * len(info_name))\n",
    "    load_quorums, load_infos = get_info_quorum(LOADS, info_name)\n",
    "    read_quorums, read_infos = get_info_quorum(READS, info_name)\n",
    "    \n",
    "    def get_quorum_strings(quorums):\n",
    "        return [f\"r={r},\\nw={w}\" for r, w in quorums]\n",
    "    \n",
    "    max_ylim = get_nested_max(load_infos, read_infos) * 1.1\n",
    "    ############ LOAD ############ \n",
    "    y = [x for li in load_infos for x in li]\n",
    "    plt.bar(list(range(len(load_quorums))), y, tick_label=get_quorum_strings(load_quorums), width=0.3, color=\"white\", edgecolor=\"black\") #, showfliers=False, whis=\"range\")\n",
    "    plt.ylabel(info_name)\n",
    "    plt.xlabel(\"Quorum configuration\")\n",
    "    plt.ylim(ymin=0, ymax=max_ylim)\n",
    "    plt.legend([\"INSERT\"])\n",
    "\n",
    "    if save_fig:\n",
    "        plt.savefig(f\"multi_load_{out_file_name}.svg\")\n",
    "        plt.savefig(f\"multi_load_{out_file_name}.pgf\")\n",
    "        plt.savefig(f\"multi_load_{out_file_name}.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    ############ READ ############    \n",
    "    z = [x for ri in read_infos for x in ri]\n",
    "    plt.bar(list(range(len(read_quorums))), z, tick_label=get_quorum_strings(load_quorums), width=0.3, color=\"white\", edgecolor=\"black\") #, showfliers=False, whis=\"range\")\n",
    "    plt.ylabel(info_name)\n",
    "    plt.xlabel(\"Quorum configuration\")\n",
    "    plt.ylim(ymin=0, ymax=max_ylim)\n",
    "    plt.legend([\"READ\"])\n",
    "\n",
    "    if save_fig:\n",
    "        plt.savefig(f\"multi_read_{out_file_name}.svg\")\n",
    "        plt.savefig(f\"multi_read_{out_file_name}.pgf\")\n",
    "        plt.savefig(f\"multi_read_{out_file_name}.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for info_name, out_file_name in INFO_NAMES:\n",
    "    plot_info_per_capacity(info_name, out_file_name, save_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for info_name, out_file_name in INFO_NAMES:\n",
    "    plot_quorum_size(info_name, out_file_name, save_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    'Throughput(ops/sec)',\n",
    "    'AverageLatency(us)',\n",
    "    '99thPercentileLatency(us)'\n",
    "]\n",
    "\n",
    "print_quorum_metrics(METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = [1545, 1579, 1597, 1621, 1636, 1668, 1700, 1764, 1807, 1834, 1907, 1957]\n",
    "dev = np.std(data)\n",
    "mean = np.mean(data)\n",
    "\n",
    "print(dev)\n",
    "print(dev / mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
