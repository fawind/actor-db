{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Amazing Benchmark Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set path to log directory here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = \"/Users/law/drive/msc/m3/adb/bm_results/bm_logs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Run all cells and all the plots will magically appear :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions 'n shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class BMRunInfo:\n",
    "    def __init__(self, bm_type, bm_infos, final_info):\n",
    "        self.bm_type = bm_type\n",
    "        self.bm_infos = bm_infos\n",
    "        self.final_info = final_info\n",
    "\n",
    "# Example line (no linebreaks)\n",
    "# 2018-08-12 18:56:45:761 10 sec: 4262 operations; 426.2 current ops/sec; est completion in 1 hour 18 minutes \n",
    "# [INSERT: Count=4266, Max=951807, Min=2522, Avg=12826.31, 90=16719, 99=58399, 99.9=947199, 99.99=951807]\n",
    "\n",
    "BM_INFO_RE = re.compile(r'^\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}:\\d{3} (\\d{2,}) sec: (\\d+) operations; (\\d*.\\d*) current ops/sec; .* \\[[A-Z]+: Count=(\\d*), Max=(\\d*), Min=(\\d*), Avg=(\\d*.\\d*|\\d*), 90=(\\d*), 99=(\\d*), 99\\.9=(\\d*), 99\\.99=(\\d*)\\]')\n",
    "\n",
    "class BMInfo:\n",
    "    def __init__(self, log_line):\n",
    "        match = BM_INFO_RE.match(log_line)\n",
    "        if match is None:\n",
    "            raise ValueError(\"Bad log line: \" + log_line)\n",
    "        self.seconds = match.group(1)\n",
    "        self.total_ops = match.group(2)\n",
    "        self.ops_per_sec = match.group(3)\n",
    "        self.ops_per_interval = match.group(4)\n",
    "        self.max_latency = match.group(5)\n",
    "        self.min_latency = match.group(6)\n",
    "        self.avg_latecny = match.group(7)\n",
    "        self.p90 = match.group(8)\n",
    "        self.p99 = match.group(9)\n",
    "        self.p999 = match.group(10)\n",
    "        self.p9999 = match.group(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bm_run_from_file(file_name):\n",
    "    bm_infos = []\n",
    "    final_info = {}\n",
    "    bm_type = \"\"\n",
    "    for line in open(file_name):\n",
    "        if line.startswith(\"2018-\") and \"0 sec: 0 operations;\" not in line:\n",
    "            bm_infos.append(BMInfo(line))\n",
    "            \n",
    "        # [INSERT], AverageLatency(us), 1851.142024\n",
    "        # [OVERALL], Throughput(ops/sec), 8293.62759124027\n",
    "        # [READ], AverageLatency(us), 1948.265838\n",
    "        elif line.startswith(\"[INSERT],\") or line.startswith(\"[OVERALL],\") or line.startswith(\"[READ],\"):\n",
    "            split_line = line.split(', ')\n",
    "            final_info[split_line[1]] = int(float(split_line[2].strip()))\n",
    "\n",
    "        if line.startswith('[INSERT]'):\n",
    "            bm_type = \"INSERT\"\n",
    "        elif line.startswith('[READ]'):\n",
    "            bm_type = \"READ\"\n",
    "            \n",
    "    assert(bm_type != \"\")\n",
    "    return BMRunInfo(bm_type, bm_infos, final_info)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_bm_runs(log_dir):\n",
    "    runs = {}\n",
    "    for file in os.listdir(log_dir):\n",
    "        if not file.endswith(\".txt\"):\n",
    "            continue\n",
    "            \n",
    "        runs[file] = get_bm_run_from_file(os.path.join(log_dir, file))\n",
    "    return runs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUNS = get_bm_runs(LOG_DIR)\n",
    "LOADS = {file: run.final_info for file, run in runs.items() if file.startswith('load')}\n",
    "READS = {file: run.final_info for file, run in runs.items() if file.startswith('read')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capacity_from_file(file):\n",
    "    # read_capacity_1000-num_stores_1.txt\n",
    "    match = re.search(r'capacity_(\\d*)', file)\n",
    "    if match is None:\n",
    "        raise ValueError(\"bad file name: \" + file)\n",
    "    \n",
    "    return int(match.group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_info_per_capacity(runs, info_name):\n",
    "    file_infos = [(file, info[info_name]) for file, info in runs.items()]\n",
    "    cap_final_infos = [(capacity_from_file(f), info) for f, info in file_infos]\n",
    "    cap_final_infos.sort(key=lambda x: x[0])\n",
    "    caps, info = list(zip(*cap_final_infos))\n",
    "    return caps, info\n",
    "\n",
    "def plot_info_per_capacity(info_name, out_file_name):\n",
    "    load_caps, load_info = get_info_per_capacity(LOADS, info_name)\n",
    "    read_caps, read_info = get_info_per_capacity(READS, info_name)\n",
    "\n",
    "    caps = list(range(len(load_caps)))\n",
    "    \n",
    "    plt.plot(caps, load_info, 'r--o', caps, read_info, 'b--^')\n",
    "    plt.ylabel(info_name)\n",
    "    plt.ylim(ymin=0)\n",
    "    \n",
    "    max_y = int(max(max(load_info), max(read_info)) * 1.1)\n",
    "    plt.axis([0, 7, 0, max_y])\n",
    "    plt.xticks(range(len(caps)), [str(x) for x in load_caps], rotation=\"vertical\")\n",
    "    \n",
    "    plt.legend([\"INSERT\", \"READ\"])\n",
    "\n",
    "    plt.savefig(f\"{out_file_name}.svg\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "info_names = [\n",
    "    ('Throughput(ops/sec)', 'throughput'),\n",
    "    ('RunTime(ms)', 'runtime'),\n",
    "    ('AverageLatency(us)', 'avg_latency'),\n",
    "    ('MinLatency(us)', 'min_latency'),\n",
    "    ('MaxLatency(us)', 'max_latency'),\n",
    "    ('95thPercentileLatency(us)', '95p_latency'),\n",
    "    ('99thPercentileLatency(us)', '99p_latecny')\n",
    "]\n",
    "\n",
    "for info_name, out_file_name in info_names:\n",
    "    plot_info_per_capacity(info_name, out_file_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
